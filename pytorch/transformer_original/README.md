# 理解Transform -- 从一个pytorch项目出发

[原文地址](https://zhuanlan.zhihu.com/p/439196812)

本系列文章希望帮助读者对Transformer以及self-attention这一结构有更加深刻的理解。由于本文主要分析transformer的相关实现代码，所以对其原理的回顾较为简要。如果您完全不了解self-attention或者transformer，强烈建议您先观看李宏毅老师关于self-attention的详细讲解：

